{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T06_MC_Esteban_Reyes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIRONqPsiD8Z"
      },
      "source": [
        "# Tarea 5\r\n",
        "## Optimización I\r\n",
        "\r\n",
        "### Esteban Reyes Saldaña"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc-CyQ_gB7td"
      },
      "source": [
        "import numpy as np\r\n",
        "import functions as func\r\n",
        "\r\n",
        "Rosembrock      = func.Rosembrock\r\n",
        "Rosembrock_Grad = func.Rosembrock_Grad\r\n",
        "Rosembrock_Hess = func.Rosembrock_Hess\r\n",
        "\r\n",
        "Wood            = func.Wood\r\n",
        "Wood_Grad       = func.Wood_Grad\r\n",
        "Wood_Hess       = func.Wood_Hess"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCgWhHywkzGy"
      },
      "source": [
        "1. Implementa los metodos de Newton y Newton Modificado.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNcPUuyhk83d"
      },
      "source": [
        "## Método de Netwon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8ItcJVeiVPV"
      },
      "source": [
        "def newton (params = []) :\r\n",
        "  # Cargo parámetros\r\n",
        "  x_k        = params['x_0']\r\n",
        "  x_k_next   = None\r\n",
        "  alpha      = params['alpha']\r\n",
        "  f          = params['f']\r\n",
        "  f_grad     = params['f_grad']\r\n",
        "  f_hess     = params['f_hess']\r\n",
        "  max_iter   = params['max_iter']\r\n",
        "  tau_x      = params['tau_x']\r\n",
        "  tau_f      = params['tau_f']\r\n",
        "  tau_f_grad = params['tau_grad']\r\n",
        "    \r\n",
        "  sub_params = {}\r\n",
        "        \r\n",
        "  # Guardo Parámetros\r\n",
        "  f_hist = []\r\n",
        "  f_hist.append(f(x_k, params = sub_params))\r\n",
        "\r\n",
        "  g_hist = []\r\n",
        "  g_hist.append(np.linalg.norm(f_grad(x_k, params = sub_params)))\r\n",
        "    \r\n",
        "  # Comienza descenso\r\n",
        "  k = 0 \r\n",
        "  while True:\r\n",
        "    # Calculo Gradiente\r\n",
        "    g_k = f_grad(x_k, params = sub_params)\r\n",
        "    # Calculo Hessiano\r\n",
        "    H_k = f_hess(x_k, params = sub_params)\r\n",
        "    # Calculo gradiente\r\n",
        "    d_k = np.linalg.solve(H_k, -g_k)      \r\n",
        "\r\n",
        "    # Calculo siguiente valor x_k+1\r\n",
        "    x_k_next = x_k + d_k   \r\n",
        "        \r\n",
        "\r\n",
        "    # Guardo Parámetros\r\n",
        "    f_hist.append(f(x_k_next, sub_params))\r\n",
        "    g_hist.append(np.linalg.norm(f_grad(x_k_next, params = sub_params)))\r\n",
        "\r\n",
        "    # Criterios de paro\r\n",
        "    if (k > max_iter) :\r\n",
        "      break           \r\n",
        "    if np.linalg.norm(x_k_next - x_k)/max(np.linalg.norm(x_k), 1.0) < tau_x :\r\n",
        "      break              \r\n",
        "    if np.abs(f(x_k_next, sub_params) - f(x_k, sub_params)) / max(np.linalg.norm(f(x_k, sub_params)), 1.0) < tau_f :\r\n",
        "      break       \r\n",
        "    if np.linalg.norm(f_grad(x_k_next, sub_params)) < tau_f_grad :\r\n",
        "      break\r\n",
        "            \r\n",
        "    # Guardo valor anterior   \r\n",
        "    x_k = x_k_next       \r\n",
        "    k   = k + 1\r\n",
        "        \r\n",
        "  return np.array(f_hist), np.array(g_hist), x_k_next"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OzLkBN26-WD"
      },
      "source": [
        "## Método de Newton Modificado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmg3F6s3JF3x"
      },
      "source": [
        "def cholesky_plus_identity(A, beta = 1e-3, max_iter = 100):\r\n",
        "  diag = np.diag(A)\r\n",
        "  min_aii = min(diag)\r\n",
        "  if min_aii > 0 :\r\n",
        "    tau = 0.0\r\n",
        "  else :\r\n",
        "    tau = - min_aii + beta\r\n",
        "\r\n",
        "  k = 0\r\n",
        "  while k < max_iter :\r\n",
        "    A = A + tau * np.eye(diag.shape[0])\r\n",
        "    try :\r\n",
        "      A = np.linalg.cholesky(A)\r\n",
        "    except :\r\n",
        "      tau = max(2.0 * tau, beta)\r\n",
        "    else :\r\n",
        "      k = max_iter\r\n",
        "    k += 1\r\n",
        "\r\n",
        "  return A"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gey06urC692D"
      },
      "source": [
        "def newton_modified (params = []) :\r\n",
        "    '''\r\n",
        "    '''\r\n",
        "    # Cargo parámetros\r\n",
        "    x_k        = params['x_0']\r\n",
        "    x_k_next   = None\r\n",
        "    f          = params['f']\r\n",
        "    f_grad     = params['f_grad']\r\n",
        "    f_hess     = params['f_hess']\r\n",
        "    max_iter   = params['max_iter']\r\n",
        "    tau_x      = params['tau_x']\r\n",
        "    tau_f      = params['tau_f']\r\n",
        "    tau_f_grad = params['tau_grad']\r\n",
        "    beta       = params['beta']\r\n",
        "    max_iter_c = params['cholesky']['max_iter']\r\n",
        "\r\n",
        "    sub_params = {}\r\n",
        "        \r\n",
        "    # Guardo Parámetros\r\n",
        "    f_hist = []\r\n",
        "    f_hist.append(f(x_k, params = sub_params))\r\n",
        "\r\n",
        "    g_hist = []\r\n",
        "    g_hist.append(np.linalg.norm(f_grad(x_k, params = sub_params)))\r\n",
        "              \r\n",
        "    # Comienza descenso\r\n",
        "    k = 0 \r\n",
        "    \r\n",
        "    while True:\r\n",
        "        # Calculo Gradiente\r\n",
        "        g_k = f_grad(x_k, params = sub_params)\r\n",
        "        # Calculo Hessiano\r\n",
        "        H_k = f_hess(x_k, params = sub_params)\r\n",
        "        # Factorizo usando Cholesky Modificado\r\n",
        "        L = cholesky_plus_identity(H_k, beta, max_iter_c)   \r\n",
        "        # Resuelvo sistema hacia atrás\r\n",
        "        y   = np.linalg.solve(L, -g_k) \r\n",
        "        d_k = np.linalg.solve(L.T, y)\r\n",
        "\r\n",
        "        # Calculo siguiente valor x_k+1\r\n",
        "        x_k_next = x_k + d_k   \r\n",
        "        \r\n",
        "        # Guardo Parámetros\r\n",
        "        f_hist.append(f(x_k_next, sub_params))\r\n",
        "        g_hist.append(np.linalg.norm(f_grad(x_k_next, sub_params)))\r\n",
        "        \r\n",
        "                  \r\n",
        "        # Criterios de paro\r\n",
        "        if (k > max_iter) :\r\n",
        "            break\r\n",
        "            \r\n",
        "        if np.linalg.norm(x_k_next - x_k)/max(np.linalg.norm(x_k), 1.0) < tau_x :\r\n",
        "            break\r\n",
        "                  \r\n",
        "        if np.abs(f(x_k_next, sub_params) - f(x_k, sub_params)) / max(np.linalg.norm(f(x_k, sub_params)), 1.0) < tau_f :\r\n",
        "            break\r\n",
        "        \r\n",
        "                  \r\n",
        "        if np.linalg.norm(f_grad(x_k_next, sub_params)) < tau_f_grad :\r\n",
        "            break\r\n",
        "            \r\n",
        "        # Guardo valor anterior   \r\n",
        "        x_k = x_k_next       \r\n",
        "        k   = k + 1\r\n",
        "        \r\n",
        "    return np.array(f_hist), np.array(g_hist), x_k_next"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFQ4H_EXUSjC"
      },
      "source": [
        "2. Realice 30 corridas, de los algoritmos de Maximo descenso, Newton y Newton Modificado a las funciones que aparecen abajo. Reporte los promedios\r\n",
        "de tiempo de ejecución y número de iteraciones, segun aparece en las tablas\r\n",
        "1 y 2. Seleccione los puntos iniciales de modo que cada entrada se obtenga\r\n",
        "de la siguiente forma\r\n",
        "\r\n",
        "$$ x_i^0 = x_i^* + \\eta $$\r\n",
        "\r\n",
        "donde $ x_i^* $ es la $i$-ésima entrada del óptimo $ x^* $ proporcionado más abajo para cada función y $ \\eta \\sim \\mathcal{U}(-1,1). $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdz-nxg1VpL3"
      },
      "source": [
        "# Métodos para Descenso Gradiente\r\n",
        "import optimization as opti\r\n",
        "import time as time\r\n",
        "\r\n",
        "back_tracking = opti.back_tracking\r\n",
        "bisection     = opti.bisection\r\n",
        "des_grad      = opti.des_grad"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1_H6xxLU6LK"
      },
      "source": [
        "## Función de Rosembrock\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bmF4G-AUQWH",
        "outputId": "a5059c86-a500-4744-b6b3-de94aa9f3b5c"
      },
      "source": [
        "iterations = 30\r\n",
        "n = 100\r\n",
        "\r\n",
        "time_backtracking       = []\r\n",
        "iterations_backtracking = []\r\n",
        "\r\n",
        "time_newton       = []\r\n",
        "iterations_newton = []\r\n",
        "\r\n",
        "time_newton_modified       = []\r\n",
        "iterations_newton_modified = []\r\n",
        "\r\n",
        "for i in range(iterations) :\r\n",
        "  print('Corrida :', i+1)\r\n",
        "\r\n",
        "  x_0 = [1.0 + np.random.uniform(-1,1) for i in range(n)]\r\n",
        "  x_0 = np.array(x_0)\r\n",
        "  # Backtracking\r\n",
        "  params = {\r\n",
        "            'x_0'      : x_0,\r\n",
        "            'f'        : Rosembrock,\r\n",
        "            'f_grad'   : Rosembrock_Grad,\r\n",
        "            'max_iter' : 10000,\r\n",
        "            'tau_x'    : 1e-12,\r\n",
        "            'tau_f'    : 1e-12,\r\n",
        "            'tau_grad' : 1e-12,\r\n",
        "            'method'      : 'BackTracking',\r\n",
        "            'BackTracking' : {\r\n",
        "                                'alpha' : 0.1,\r\n",
        "                                'ro'    : 0.1,\r\n",
        "                                'c1'    : 1e-4\r\n",
        "                             }\r\n",
        "          }\r\n",
        "  print('Descenso Gradiente...')\r\n",
        "  # Mido tiempo\r\n",
        "  star                = time.time()\r\n",
        "  f_hist, g_hist, x_k = des_grad(params)\r\n",
        "  ex_time             = time.time() - star  \r\n",
        "\r\n",
        "  time_backtracking.append(ex_time)\r\n",
        "  iterations_backtracking.append(f_hist.shape[0])\r\n",
        "\r\n",
        "  # Newton \r\n",
        "  params = {\r\n",
        "            'x_0'      : x_0,\r\n",
        "            'f'        : Rosembrock,\r\n",
        "            'f_grad'   : Rosembrock_Grad,\r\n",
        "            'f_hess'   : Rosembrock_Hess,\r\n",
        "            'max_iter' : 10000,\r\n",
        "            'tau_x'    : 1e-8,\r\n",
        "            'tau_f'    : 1e-8,\r\n",
        "            'tau_grad' : 1e-8,\r\n",
        "            'alpha'    : 0.5\r\n",
        "          }\r\n",
        "  print('Newton ...')\r\n",
        "  # Mido tiempo\r\n",
        "  star                = time.time()\r\n",
        "  f_hist, g_hist, x_k = newton(params)\r\n",
        "  ex_time             = time.time() - star  \r\n",
        "\r\n",
        "  time_newton.append(ex_time)\r\n",
        "  iterations_newton.append(f_hist.shape[0])\r\n",
        "    \r\n",
        "  # Newton Modificado\r\n",
        "  params = {\r\n",
        "              'x_0'      : x_0,\r\n",
        "              'f'        : Rosembrock,\r\n",
        "              'f_grad'   : Rosembrock_Grad,\r\n",
        "              'f_hess'   : Rosembrock_Hess,\r\n",
        "              'max_iter' : 10000,\r\n",
        "              'tau_x'    : 1e-8,\r\n",
        "              'tau_f'    : 1e-8,\r\n",
        "              'tau_grad' : 1e-8,\r\n",
        "              'beta'     : 1e-3,\r\n",
        "              'cholesky' : {\r\n",
        "                            'max_iter' : 100\r\n",
        "                            }\r\n",
        "            }\r\n",
        "  print('Newton Modificado ...')\r\n",
        "  # Mido tiempo\r\n",
        "  star                = time.time()\r\n",
        "  f_hist, g_hist, x_k = newton_modified(params)\r\n",
        "  ex_time             = time.time() - star  \r\n",
        "\r\n",
        "  time_newton_modified.append(ex_time)\r\n",
        "  iterations_newton_modified.append(f_hist.shape[0])\r\n",
        "\r\n",
        "    \r\n",
        "print('Backtracking:')\r\n",
        "print('Tiempo promedio: ', np.mean(time_backtracking), ' Promedio de iteraciones : ', np.mean(iterations_backtracking))\r\n",
        "print('Newton:')\r\n",
        "print('Tiempo promedio: ', np.mean(time_newton), ' Promedio de iteraciones : ', np.mean(iterations_newton))\r\n",
        "print('Newton Modificado:')\r\n",
        "print('Tiempo promedio: ', np.mean(time_newton_modified), ' Promedio de iteraciones : ', np.mean(iterations_newton_modified))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corrida : 1\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 2\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 3\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 4\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 5\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 6\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 7\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 8\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 9\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 10\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 11\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 12\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 13\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 14\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 15\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 16\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 17\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 18\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 19\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 20\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 21\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 22\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 23\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 24\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 25\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 26\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 27\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 28\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 29\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 30\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Backtracking:\n",
            "Tiempo promedio:  123.31663033962249  Promedio de iteraciones :  10003.0\n",
            "Newton:\n",
            "Tiempo promedio:  12.319897222518922  Promedio de iteraciones :  3599.7\n",
            "Newton Modificado:\n",
            "Tiempo promedio:  28.564459244410198  Promedio de iteraciones :  7468.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVpKEssdxuJQ"
      },
      "source": [
        "## Función de Wood"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLmXfTuexuJY",
        "outputId": "d621b8f5-e94a-4642-c4dd-866d7ee2d149"
      },
      "source": [
        "iterations = 30\r\n",
        "n = 4\r\n",
        "\r\n",
        "time_backtracking       = []\r\n",
        "iterations_backtracking = []\r\n",
        "\r\n",
        "time_newton       = []\r\n",
        "iterations_newton = []\r\n",
        "\r\n",
        "time_newton_modified       = []\r\n",
        "iterations_newton_modified = []\r\n",
        "\r\n",
        "for i in range(iterations) :\r\n",
        "  print('Corrida :', i+1)\r\n",
        "\r\n",
        "  x_0 = [1.0 + np.random.uniform(-1,1) for i in range(n)]\r\n",
        "  x_0 = np.array(x_0)\r\n",
        "  # Backtracking\r\n",
        "  params = {\r\n",
        "            'x_0'      : x_0,\r\n",
        "            'f'        : Wood,\r\n",
        "            'f_grad'   : Wood_Grad,\r\n",
        "            'max_iter' : 10000,\r\n",
        "            'tau_x'    : 1e-8,\r\n",
        "            'tau_f'    : 1e-8,\r\n",
        "            'tau_grad' : 1e-8,\r\n",
        "            'method'      : 'BackTracking',\r\n",
        "            'BackTracking' : {\r\n",
        "                                'alpha' : 0.1,\r\n",
        "                                'ro'    : 0.1,\r\n",
        "                                'c1'    : 1e-4\r\n",
        "                             }\r\n",
        "          }\r\n",
        "  print('Descenso Gradiente...')\r\n",
        "  # Mido tiempo\r\n",
        "  star                = time.time()\r\n",
        "  f_hist, g_hist, x_k = des_grad(params)\r\n",
        "  ex_time             = time.time() - star  \r\n",
        "\r\n",
        "  time_backtracking.append(ex_time)\r\n",
        "  iterations_backtracking.append(f_hist.shape[0])\r\n",
        "\r\n",
        "  # Newton \r\n",
        "  params = {\r\n",
        "            'x_0'      : x_0,\r\n",
        "            'f'        : Wood,\r\n",
        "            'f_grad'   : Wood_Grad,\r\n",
        "            'f_hess'   : Wood_Hess,\r\n",
        "            'max_iter' : 10000,\r\n",
        "            'tau_x'    : 1e-8,\r\n",
        "            'tau_f'    : 1e-8,\r\n",
        "            'tau_grad' : 1e-8,\r\n",
        "            'alpha'    : 0.5\r\n",
        "          }\r\n",
        "  print('Newton ...')\r\n",
        "  # Mido tiempo\r\n",
        "  star                = time.time()\r\n",
        "  f_hist, g_hist, x_k = newton(params)\r\n",
        "  ex_time             = time.time() - star  \r\n",
        "\r\n",
        "  time_newton.append(ex_time)\r\n",
        "  iterations_newton.append(f_hist.shape[0])\r\n",
        "    \r\n",
        "  # Newton Modificado\r\n",
        "  params = {\r\n",
        "              'x_0'      : x_0,\r\n",
        "              'f'        : Wood,\r\n",
        "              'f_grad'   : Wood_Grad,\r\n",
        "              'f_hess'   : Wood_Hess,\r\n",
        "              'max_iter' : 10000,\r\n",
        "              'tau_x'    : 1e-8,\r\n",
        "              'tau_f'    : 1e-8,\r\n",
        "              'tau_grad' : 1e-8,\r\n",
        "              'beta'     : 1e-3,\r\n",
        "              'cholesky' : {\r\n",
        "                            'max_iter' : 100\r\n",
        "                            }\r\n",
        "            }\r\n",
        "  print('Newton Modificado ...')\r\n",
        "  # Mido tiempo\r\n",
        "  star                = time.time()\r\n",
        "  f_hist, g_hist, x_k = newton_modified(params)\r\n",
        "  ex_time             = time.time() - star  \r\n",
        "\r\n",
        "  time_newton_modified.append(ex_time)\r\n",
        "  iterations_newton_modified.append(f_hist.shape[0])\r\n",
        "\r\n",
        "    \r\n",
        "print('Backtracking:')\r\n",
        "print('Tiempo promedio: ', np.mean(time_backtracking), ' Promedio de iteraciones : ', np.mean(iterations_backtracking))\r\n",
        "print('Newton:')\r\n",
        "print('Tiempo promedio: ', np.mean(time_newton), ' Promedio de iteraciones : ', np.mean(iterations_newton))\r\n",
        "print('Newton Modificado:')\r\n",
        "print('Tiempo promedio: ', np.mean(time_newton_modified), ' Promedio de iteraciones : ', np.mean(iterations_newton_modified))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corrida : 1\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 2\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 3\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 4\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 5\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 6\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 7\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 8\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 9\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 10\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 11\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 12\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 13\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 14\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 15\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 16\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 17\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 18\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 19\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 20\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 21\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 22\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 23\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 24\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 25\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 26\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 27\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 28\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 29\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Corrida : 30\n",
            "Descenso Gradiente...\n",
            "Newton ...\n",
            "Newton Modificado ...\n",
            "Backtracking:\n",
            "Tiempo promedio:  6.731847929954529  Promedio de iteraciones :  9479.466666666667\n",
            "Newton:\n",
            "Tiempo promedio:  0.016019535064697266  Promedio de iteraciones :  102.03333333333333\n",
            "Newton Modificado:\n",
            "Tiempo promedio:  0.02209479808807373  Promedio de iteraciones :  98.13333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}